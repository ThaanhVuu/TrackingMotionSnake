import multiprocessing
import torch
from ultralytics import YOLO


def main():
    # ğŸ” Kiá»ƒm tra GPU kháº£ dá»¥ng
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        print(f"âœ… CÃ³ {device_count} GPU kháº£ dá»¥ng.")

        # ğŸ§  Tá»± Ä‘á»™ng chá»n GPU ráº£nh (Ã­t memory usage nháº¥t)
        min_used = None
        selected_gpu = 0
        for i in range(device_count):
            mem_info = torch.cuda.mem_get_info(i)
            free_mem = mem_info[0] / mem_info[1]  # pháº§n trÄƒm bá»™ nhá»› trá»‘ng
            print(f"GPU {i}: {free_mem * 100:.2f}% bá»™ nhá»› trá»‘ng.")
            if (min_used is None) or (free_mem > min_used):
                min_used = free_mem
                selected_gpu = i
        device = selected_gpu
        print(f"ğŸ¯ Sá»­ dá»¥ng GPU {device} Ä‘á»ƒ train.")
    else:
        device = "cpu"
        print("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n GPU, sáº½ train báº±ng CPU (ráº¥t cháº­m).")

    # ğŸ§© Load model
    model = YOLO("yolo11n.pt")

    # ğŸš€ Train
    results = model.train(
        data="../dataset/data.yaml",
        epochs=100,
        imgsz=1280,
        device=device,  # GPU tá»± chá»n
        workers=0,  # giáº£m lá»—i multiprocessing trÃªn Windows
        name="train_auto",  # tÃªn run
        deterministic=True  # káº¿t quáº£ á»•n Ä‘á»‹nh
    )


if __name__ == "__main__":
    multiprocessing.freeze_support()  # Báº¯t buá»™c trÃªn Windows
    main()
